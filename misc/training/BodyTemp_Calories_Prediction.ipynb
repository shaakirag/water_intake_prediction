{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYMBkgOoOGpJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "import warnings\n",
        "from warnings import filterwarnings\n",
        "import tensorflow as tf\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import shap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    df1 = pd.read_csv(\"calories.csv\")\n",
        "    df2 = pd.read_csv(\"exercise.csv\")\n",
        "    df = pd.concat([df2, df1[\"Calories\"]], axis=1)\n",
        "    df.drop(columns=[\"User_ID\"], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def process_features(df):\n",
        "    # One-hot encoding\n",
        "    categorical = pd.get_dummies(df[\"Gender\"], drop_first=True)\n",
        "    numerical = df.select_dtypes(include=np.number)\n",
        "    return pd.concat([categorical, numerical], axis=1)"
      ],
      "metadata": {
        "id": "JINaAOXeQLcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature analysis visualizations\n",
        "def create_visualizations(data):\n",
        "    # Numerical distributions\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    plotnumber = 1\n",
        "    num_cols = data.columns[1:]  # Skip Male column\n",
        "\n",
        "    for col in num_cols:\n",
        "        if plotnumber <= 8:\n",
        "            ax = plt.subplot(3, 3, plotnumber)\n",
        "            sns.histplot(data[col], kde=True)\n",
        "            plt.xlabel(col, fontsize=12)\n",
        "            plotnumber += 1\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('numerical_distributions.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Correlation heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(data.corr(), cmap='Blues', annot=True)\n",
        "    plt.title('Feature Correlation')\n",
        "    plt.savefig('correlation_heatmap.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "KVSW8xvhQB-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_body_temp_model(X_train, X_test, y_train, y_test):\n",
        "    def predict(ml_model, model_name):\n",
        "        model = ml_model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        print(f'\\n{model_name} Performance (Body Temp Prediction):')\n",
        "        print(f'R2 Score: {metrics.r2_score(y_test, y_pred):.4f}')\n",
        "        print(f'MAE: {metrics.mean_absolute_error(y_test, y_pred):.2f}')\n",
        "        print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred)):.2f}')\n",
        "        return model\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training Body Temperature Models\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    models = {\n",
        "        'XGBRegressor': XGBRegressor(),\n",
        "        'LinearRegression': LinearRegression(),\n",
        "        'DecisionTree': DecisionTreeRegressor(),\n",
        "        'RandomForest': RandomForestRegressor()\n",
        "    }\n",
        "\n",
        "    best_model = None\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for name, model in models.items():\n",
        "        current_model = predict(model, name)\n",
        "        score = metrics.r2_score(y_test, current_model.predict(X_test))\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_model = current_model\n",
        "\n",
        "    return best_model\n"
      ],
      "metadata": {
        "id": "k5h68n3OQPtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_calorie_model(X_train, X_test, y_train, y_test):\n",
        "    def predict(ml_model, model_name):\n",
        "        model = ml_model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        print(f'\\n{model_name} Performance (Calorie Prediction):')\n",
        "        print(f'R2 Score: {metrics.r2_score(y_test, y_pred):.4f}')\n",
        "        print(f'MAE: {metrics.mean_absolute_error(y_test, y_pred):.2f}')\n",
        "        print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred)):.2f}')\n",
        "        return model\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training Calorie Models\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    models = {\n",
        "        'XGBRegressor': XGBRegressor(),\n",
        "        'LinearRegression': LinearRegression(),\n",
        "        'DecisionTree': DecisionTreeRegressor(),\n",
        "        'RandomForest': RandomForestRegressor()\n",
        "    }\n",
        "\n",
        "    best_model = None\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for name, model in models.items():\n",
        "        current_model = predict(model, name)\n",
        "        score = metrics.r2_score(y_test, current_model.predict(X_test))\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_model = current_model\n",
        "\n",
        "    return best_model\n"
      ],
      "metadata": {
        "id": "vhzUQruPQTi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model Definitions\n",
        "def build_body_temp_nn(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def build_calorie_nn(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def train_nn_body_temp(X_train, X_val, y_train, y_val):\n",
        "    model = build_body_temp_nn(X_train.shape[1])\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_nn_calorie(X_train, X_val, y_train, y_val):\n",
        "    model = build_calorie_nn(X_train.shape[1])\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JhQykZ1tTTEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_with_shap(model, X_data, feature_names, model_type='traditional', title_suffix=\"\"):\n",
        "    print(f\"\\nGenerating SHAP explanations ({model_type})...\")\n",
        "    sample = X_data.sample(min(100, len(X_data)), random_state=1)\n",
        "\n",
        "    try:\n",
        "        sample_array = sample.values.astype(np.float32)\n",
        "\n",
        "        if model_type == 'traditional':\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "        elif model_type == 'neural_net':\n",
        "            bg_sample_size = min(50, sample_array.shape[0])\n",
        "            # Use permutation to avoid issues with np.random.choice\n",
        "            indices = np.random.permutation(sample_array.shape[0])[:bg_sample_size]\n",
        "            background = sample_array[indices]\n",
        "            explainer = shap.DeepExplainer(model, background)\n",
        "\n",
        "        shap_values = explainer.shap_values(sample_array)\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values = shap_values[0]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, sample_array, feature_names=feature_names, show=False)\n",
        "        plt.savefig(f'shap_summary_{title_suffix}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        expected_value = explainer.expected_value\n",
        "        if isinstance(expected_value, list):\n",
        "            expected_value = expected_value[0]\n",
        "        if isinstance(expected_value, np.ndarray) and expected_value.size == 1:\n",
        "            expected_value = expected_value.item()\n",
        "\n",
        "        force_instance = sample_array[0]\n",
        "        plt.figure()\n",
        "        shap.force_plot(expected_value, shap_values[0], force_instance,\n",
        "                        feature_names=feature_names, matplotlib=True, show=False)\n",
        "        plt.savefig(f'shap_force_{title_suffix}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"SHAP Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "gqaG9j10o4tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(X_body_train, X_body_val, y_body_train, y_body_val, y_cal_train, y_cal_val):\n",
        "    \"\"\"Train all models and return them\"\"\"\n",
        "    # Train body temperature models\n",
        "    body_temp_model = train_body_temp_model(X_body_train, X_body_val, y_body_train, y_body_val)\n",
        "    body_temp_nn = train_nn_body_temp(X_body_train, X_body_val, y_body_train, y_body_val)\n",
        "\n",
        "    # Generate body temperature predictions\n",
        "    def generate_predictions(model, nn_model, X):\n",
        "        return {\n",
        "            'traditional': model.predict(X),\n",
        "            'neural_net': nn_model.predict(X).flatten()\n",
        "        }\n",
        "\n",
        "    body_temp_train_preds = generate_predictions(body_temp_model, body_temp_nn, X_body_train)\n",
        "    body_temp_val_preds = generate_predictions(body_temp_model, body_temp_nn, X_body_val)\n",
        "\n",
        "    # Create calorie features\n",
        "    def create_calorie_features(X, preds):\n",
        "        return X.assign(\n",
        "            Predicted_Body_Temp_Traditional=preds['traditional'],\n",
        "            Predicted_Body_Temp_NN=preds['neural_net']\n",
        "        )\n",
        "\n",
        "    X_cal_train = create_calorie_features(X_body_train, body_temp_train_preds)\n",
        "    X_cal_val = create_calorie_features(X_body_val, body_temp_val_preds)\n",
        "\n",
        "    # Train calorie models\n",
        "    calorie_model = train_calorie_model(\n",
        "        X_cal_train.drop(columns=['Predicted_Body_Temp_NN']),\n",
        "        X_cal_val.drop(columns=['Predicted_Body_Temp_NN']),\n",
        "        y_cal_train,\n",
        "        y_cal_val\n",
        "    )\n",
        "    calorie_nn = train_nn_calorie(X_cal_train, X_cal_val, y_cal_train, y_cal_val)\n",
        "\n",
        "    return body_temp_model, body_temp_nn, calorie_model, calorie_nn\n",
        "\n",
        "def test_models(models, X_body_test, y_body_test, X_cal_test_raw, y_cal_test):\n",
        "    \"\"\"Evaluate models and return test predictions\"\"\"\n",
        "    body_temp_model, body_temp_nn, calorie_model, calorie_nn = models\n",
        "\n",
        "    # Body temperature predictions\n",
        "    body_temp_test_preds = {\n",
        "        'traditional': body_temp_model.predict(X_body_test),\n",
        "        'neural_net': body_temp_nn.predict(X_body_test).flatten()\n",
        "    }\n",
        "\n",
        "    # Create calorie features for test set\n",
        "    X_cal_test = X_cal_test_raw.assign(\n",
        "        Predicted_Body_Temp_Traditional=body_temp_test_preds['traditional'],\n",
        "        Predicted_Body_Temp_NN=body_temp_test_preds['neural_net']\n",
        "    )\n",
        "\n",
        "    # Calorie predictions\n",
        "    calorie_preds = {\n",
        "        'traditional': calorie_model.predict(X_cal_test.drop(columns=['Predicted_Body_Temp_NN'])),\n",
        "        'neural_net': calorie_nn.predict(X_cal_test).flatten()\n",
        "    }\n",
        "\n",
        "    return body_temp_test_preds, calorie_preds, X_cal_test\n",
        "\n",
        "def generate_shap(models, X_body_sample, X_cal_sample):\n",
        "    \"\"\"Generate SHAP explanations for all models\"\"\"\n",
        "    body_temp_model, body_temp_nn, calorie_model, calorie_nn = models\n",
        "\n",
        "    # Body temperature explanations\n",
        "    explain_with_shap(\n",
        "        body_temp_model,\n",
        "        X_body_sample,\n",
        "        feature_names=X_body_sample.columns.tolist(),\n",
        "        model_type='traditional',\n",
        "        title_suffix=\"Body_Temp_Traditional\"\n",
        "    )\n",
        "    explain_with_shap(\n",
        "        body_temp_nn,\n",
        "        X_body_sample,\n",
        "        feature_names=X_body_sample.columns.tolist(),\n",
        "        model_type='neural_net',\n",
        "        title_suffix=\"Body_Temp_NeuralNet\"\n",
        "    )\n",
        "\n",
        "    # Calorie explanations\n",
        "    explain_with_shap(\n",
        "        calorie_model,\n",
        "        X_cal_sample.drop(columns=['Predicted_Body_Temp_NN']),\n",
        "        feature_names=X_cal_sample.drop(columns=['Predicted_Body_Temp_NN']).columns.tolist(),\n",
        "        model_type='traditional',\n",
        "        title_suffix=\"Calorie_Traditional\"\n",
        "    )\n",
        "    explain_with_shap(\n",
        "        calorie_nn,\n",
        "        X_cal_sample,\n",
        "        feature_names=X_cal_sample.columns.tolist(),\n",
        "        model_type='neural_net',\n",
        "        title_suffix=\"Calorie_NeuralNet\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "tgqOwS15kHz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions_heatmap(y_true, y_pred, model_label, task):\n",
        "    \"\"\"\n",
        "    Creates and saves a heatmap comparing the true and predicted values.\n",
        "    \"\"\"\n",
        "    heatmap_data, xedges, yedges = np.histogram2d(y_true, y_pred, bins=30)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(heatmap_data.T, cmap=\"coolwarm\", annot=False)\n",
        "    plt.xlabel(f\"True {task}\")\n",
        "    plt.ylabel(f\"Predicted {task}\")\n",
        "    plt.title(f\"Heatmap of {task} Predictions ({model_label})\")\n",
        "    plt.savefig(f\"heatmap_{task}_{model_label}.png\", bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(model, feature_names, model_label, task):\n",
        "    \"\"\"\n",
        "    Plots and saves a bar plot of feature importances or coefficients (if available).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "        elif hasattr(model, 'coef_'):\n",
        "            importances = model.coef_\n",
        "        else:\n",
        "            print(f\"No feature importance available for {model_label}\")\n",
        "            return\n",
        "        fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "        fi_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Importance', y='Feature', data=fi_df)\n",
        "        plt.title(f'Feature Importance for {model_label} ({task})')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'feature_importance_{task}_{model_label}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting feature importance for {model_label}: {e}\")\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    \"\"\"Helper function to print metrics\"\"\"\n",
        "    print(f\"R2 Score: {metrics.r2_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"MAE: {metrics.mean_absolute_error(y_true, y_pred):.2f}\")\n",
        "    print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(y_true, y_pred)):.2f}\")"
      ],
      "metadata": {
        "id": "jot0q0QHwRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train and test\n",
        "def main():\n",
        "    # Data processing\n",
        "    df = load_data()\n",
        "    processed_data = process_features(df)\n",
        "\n",
        "    create_visualizations(processed_data)\n",
        "\n",
        "    # Split data\n",
        "    temp_data, final_test_data = train_test_split(processed_data, test_size=0.2, random_state=1)\n",
        "    X_body = temp_data.drop(columns=['Calories', 'Body_Temp'])\n",
        "    y_body = temp_data['Body_Temp']\n",
        "\n",
        "    # Train/val split\n",
        "    X_body_train, X_body_val, y_body_train, y_body_val = train_test_split(\n",
        "        X_body, y_body, test_size=0.25, random_state=1)\n",
        "\n",
        "    # Train models\n",
        "    models = train_models(\n",
        "        X_body_train, X_body_val,\n",
        "        y_body_train, y_body_val,\n",
        "        temp_data.loc[X_body_train.index]['Calories'],\n",
        "        temp_data.loc[X_body_val.index]['Calories']\n",
        "    )\n",
        "\n",
        "    # Prepare test data\n",
        "    X_body_test = final_test_data.drop(columns=['Calories', 'Body_Temp'])\n",
        "    y_body_test = final_test_data['Body_Temp']\n",
        "    y_cal_test = final_test_data['Calories']\n",
        "\n",
        "    # Test models\n",
        "    body_temp_preds, calorie_preds, X_cal_test = test_models(\n",
        "        models, X_body_test, y_body_test,\n",
        "        final_test_data.drop(columns=['Calories', 'Body_Temp']),\n",
        "        y_cal_test\n",
        "    )\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Final Test Set Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Body temperature metrics\n",
        "    for model_type in ['traditional', 'neural_net']:\n",
        "        print(f\"\\nBody Temperature ({model_type}):\")\n",
        "        print_metrics(y_body_test, body_temp_preds[model_type])\n",
        "\n",
        "    # Calorie metrics\n",
        "    for model_type in ['traditional', 'neural_net']:\n",
        "        print(f\"\\nCalorie Prediction ({model_type}):\")\n",
        "        print_metrics(y_cal_test, calorie_preds[model_type])\n",
        "\n",
        "    # Save models\n",
        "    with open('body_temp_model.pkl', 'wb') as f:\n",
        "        pickle.dump(models[0], f)\n",
        "    with open('calorie_model.pkl', 'wb') as f:\n",
        "        pickle.dump(models[2], f)\n",
        "    models[1].save('body_temp_nn.h5')\n",
        "    models[3].save('calorie_nn.h5')\n",
        "\n",
        "    # SHAP explanations\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Generating SHAP Explanations\")\n",
        "    print(\"=\"*50)\n",
        "    generate_shap(\n",
        "        models,\n",
        "        X_body_test.sample(100, random_state=1),\n",
        "        X_cal_test.sample(100, random_state=1)\n",
        "    )\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    \"\"\"Helper function to print metrics\"\"\"\n",
        "    print(f\"R2 Score: {metrics.r2_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"MAE: {metrics.mean_absolute_error(y_true, y_pred):.2f}\")\n",
        "    print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(y_true, y_pred)):.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XbI3to40lqVF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}