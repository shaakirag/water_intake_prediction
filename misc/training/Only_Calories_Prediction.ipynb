{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3CpnFDHDfmN1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "import warnings\n",
        "from warnings import filterwarnings\n",
        "import tensorflow as tf\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import shap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "filterwarnings(\"ignore\")\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    df1 = pd.read_csv(\"calories.csv\")\n",
        "    df2 = pd.read_csv(\"exercise.csv\")\n",
        "    df = pd.concat([df2, df1[\"Calories\"]], axis=1)\n",
        "    df.drop(columns=[\"User_ID\"], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def process_features(df):\n",
        "    # One-hot encoding\n",
        "    categorical = pd.get_dummies(df[\"Gender\"], drop_first=True)\n",
        "    numerical = df.select_dtypes(include=np.number)\n",
        "    return pd.concat([categorical, numerical], axis=1)"
      ],
      "metadata": {
        "id": "0y5iMpESg4_D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature analysis visualizations\n",
        "def create_visualizations(data):\n",
        "    # Numerical distributions\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    plotnumber = 1\n",
        "    num_cols = data.columns[1:]  # Skip Male column\n",
        "\n",
        "    for col in num_cols:\n",
        "        if plotnumber <= 8:\n",
        "            ax = plt.subplot(3, 3, plotnumber)\n",
        "            sns.histplot(data[col], kde=True)\n",
        "            plt.xlabel(col, fontsize=12)\n",
        "            plotnumber += 1\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('numerical_distributions.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Correlation heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(data.corr(), cmap='Blues', annot=True)\n",
        "    plt.title('Feature Correlation')\n",
        "    plt.savefig('correlation_heatmap.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "F2hLWvzjg-dT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_with_shap(model, X_data, feature_names, model_type='traditional', title_suffix=\"\"):\n",
        "    print(f\"\\nGenerating SHAP explanations ({model_type})...\")\n",
        "    sample = X_data.sample(min(100, len(X_data)), random_state=1)\n",
        "\n",
        "    try:\n",
        "        sample_array = sample.values.astype(np.float32)\n",
        "\n",
        "        if model_type == 'traditional':\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "        elif model_type == 'neural_net':\n",
        "            bg_sample_size = min(50, sample_array.shape[0])\n",
        "            # Use permutation to avoid issues with np.random.choice\n",
        "            indices = np.random.permutation(sample_array.shape[0])[:bg_sample_size]\n",
        "            background = sample_array[indices]\n",
        "            explainer = shap.DeepExplainer(model, background)\n",
        "\n",
        "        shap_values = explainer.shap_values(sample_array)\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values = shap_values[0]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, sample_array, feature_names=feature_names, show=False)\n",
        "        plt.savefig(f'shap_summary_{title_suffix}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        expected_value = explainer.expected_value\n",
        "        if isinstance(expected_value, list):\n",
        "            expected_value = expected_value[0]\n",
        "        if isinstance(expected_value, np.ndarray) and expected_value.size == 1:\n",
        "            expected_value = expected_value.item()\n",
        "\n",
        "        force_instance = sample_array[0]\n",
        "        plt.figure()\n",
        "        shap.force_plot(expected_value, shap_values[0], force_instance,\n",
        "                        feature_names=feature_names, matplotlib=True, show=False)\n",
        "        plt.savefig(f'shap_force_{title_suffix}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"SHAP Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "Wue1NVzVhOSe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions_heatmap(y_true, y_pred, model_label, task):\n",
        "    \"\"\"\n",
        "    Creates and saves a heatmap comparing the true and predicted values.\n",
        "    \"\"\"\n",
        "    heatmap_data, xedges, yedges = np.histogram2d(y_true, y_pred, bins=30)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(heatmap_data.T, cmap=\"coolwarm\", annot=False)\n",
        "    plt.xlabel(f\"True {task}\")\n",
        "    plt.ylabel(f\"Predicted {task}\")\n",
        "    plt.title(f\"Heatmap of {task} Predictions ({model_label})\")\n",
        "    plt.savefig(f\"heatmap_{task}_{model_label}.png\", bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_feature_importance(model, feature_names, model_label, task):\n",
        "    \"\"\"\n",
        "    Plots and saves a bar plot of feature importances or coefficients (if available).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "        elif hasattr(model, 'coef_'):\n",
        "            importances = model.coef_\n",
        "        else:\n",
        "            print(f\"No feature importance available for {model_label}\")\n",
        "            return\n",
        "        fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "        fi_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Importance', y='Feature', data=fi_df)\n",
        "        plt.title(f'Feature Importance for {model_label} ({task})')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'feature_importance_{task}_{model_label}.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting feature importance for {model_label}: {e}\")"
      ],
      "metadata": {
        "id": "NFO_xzmUiRw_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Model Definitions\n",
        "def build_calorie_nn(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def train_nn_calorie(X_train, X_val, y_train, y_val):\n",
        "    model = build_calorie_nn(X_train.shape[1])\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "I-UsPAqGhIKQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_calorie_nn(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def train_calorie_model(X_train, X_test, y_train, y_test):\n",
        "    def predict(ml_model, model_name):\n",
        "        model = ml_model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        print(f'\\n{model_name} Performance (Calorie Prediction):')\n",
        "        print(f'R2 Score: {metrics.r2_score(y_test, y_pred):.4f}')\n",
        "        print(f'MAE: {metrics.mean_absolute_error(y_test, y_pred):.2f}')\n",
        "        print(f'RMSE: {np.sqrt(metrics.mean_squared_error(y_test, y_pred)):.2f}')\n",
        "        return model\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training Calorie Models\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    models = {\n",
        "        'XGBRegressor': XGBRegressor(),\n",
        "        'LinearRegression': LinearRegression(),\n",
        "        'DecisionTree': DecisionTreeRegressor(),\n",
        "        'RandomForest': RandomForestRegressor()\n",
        "    }\n",
        "\n",
        "    best_model = None\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for name, model in models.items():\n",
        "        current_model = predict(model, name)\n",
        "        score = metrics.r2_score(y_test, current_model.predict(X_test))\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_model = current_model\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def train_models(X_train, X_val, y_train, y_val):\n",
        "    \"\"\"Train all models and return them\"\"\"\n",
        "    # Train calorie models\n",
        "    calorie_model = train_calorie_model(X_train, X_val, y_train, y_val)\n",
        "    calorie_nn = train_nn_calorie(X_train, X_val, y_train, y_val)\n",
        "\n",
        "    return calorie_model, calorie_nn\n",
        "\n",
        "def test_models(models, X_test, y_test):\n",
        "    \"\"\"Evaluate models and return test predictions\"\"\"\n",
        "    calorie_model, calorie_nn = models\n",
        "\n",
        "    return {\n",
        "        'traditional': calorie_model.predict(X_test),\n",
        "        'neural_net': calorie_nn.predict(X_test).flatten()\n",
        "    }\n",
        "\n",
        "def generate_shap(models, X_sample):\n",
        "    \"\"\"Generate SHAP explanations for all models\"\"\"\n",
        "    calorie_model, calorie_nn = models\n",
        "\n",
        "    # Calorie explanations\n",
        "    explain_with_shap(\n",
        "        calorie_model,\n",
        "        X_sample,\n",
        "        feature_names=X_sample.columns.tolist(),\n",
        "        model_type='traditional',\n",
        "        title_suffix=\"Calorie_Traditional\"\n",
        "    )\n",
        "    explain_with_shap(\n",
        "        calorie_nn,\n",
        "        X_sample,\n",
        "        feature_names=X_sample.columns.tolist(),\n",
        "        model_type='neural_net',\n",
        "        title_suffix=\"Calorie_NeuralNet\"\n",
        "    )\n",
        "\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    \"\"\"Helper function to print metrics\"\"\"\n",
        "    print(f\"R2 Score: {metrics.r2_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"MAE: {metrics.mean_absolute_error(y_true, y_pred):.2f}\")\n",
        "    print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(y_true, y_pred)):.2f}\")"
      ],
      "metadata": {
        "id": "b1i85WYtiWWq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Data processing\n",
        "    df = load_data()\n",
        "    processed_data = process_features(df)\n",
        "\n",
        "    create_visualizations(processed_data)\n",
        "\n",
        "    # Split data (remove Body_Temp and Height from features)\n",
        "    temp_data, final_test_data = train_test_split(\n",
        "        processed_data.drop(columns=['Body_Temp', 'Height']),  # Remove unused columns\n",
        "        test_size=0.2,\n",
        "        random_state=1\n",
        "    )\n",
        "\n",
        "    X = temp_data.drop(columns=['Calories'])\n",
        "    y = temp_data['Calories']\n",
        "\n",
        "    # Train/val split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "    # Train models\n",
        "    models = train_models(X_train, X_val, y_train, y_val)\n",
        "\n",
        "    # Prepare test data\n",
        "    X_test = final_test_data.drop(columns=['Calories'])\n",
        "    y_test = final_test_data['Calories']\n",
        "\n",
        "    # Test models\n",
        "    calorie_preds = test_models(models, X_test, y_test)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Final Test Set Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for model_type in ['traditional', 'neural_net']:\n",
        "        print(f\"\\nCalorie Prediction ({model_type}):\")\n",
        "        print_metrics(y_test, calorie_preds[model_type])\n",
        "\n",
        "    # Save models\n",
        "    with open('calorie_model.pkl', 'wb') as f:\n",
        "        pickle.dump(models[0], f)\n",
        "    models[1].save('calorie_nn.h5')\n",
        "\n",
        "    # SHAP explanations\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Generating SHAP Explanations\")\n",
        "    print(\"=\"*50)\n",
        "    generate_shap(models, X_test.sample(100, random_state=1))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ON6bWpemibxU",
        "outputId": "be148f6f-7f92-4ca1-bdb1-adadaf81c6b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training Calorie Models\n",
            "==================================================\n",
            "\n",
            "XGBRegressor Performance (Calorie Prediction):\n",
            "R2 Score: 0.9988\n",
            "MAE: 1.49\n",
            "RMSE: 2.17\n",
            "\n",
            "LinearRegression Performance (Calorie Prediction):\n",
            "R2 Score: 0.9581\n",
            "MAE: 9.67\n",
            "RMSE: 12.88\n",
            "\n",
            "DecisionTree Performance (Calorie Prediction):\n",
            "R2 Score: 0.9924\n",
            "MAE: 3.43\n",
            "RMSE: 5.47\n",
            "\n",
            "RandomForest Performance (Calorie Prediction):\n",
            "R2 Score: 0.9977\n",
            "MAE: 1.84\n",
            "RMSE: 3.02\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Final Test Set Evaluation\n",
            "==================================================\n",
            "\n",
            "Calorie Prediction (traditional):\n",
            "R2 Score: 0.9986\n",
            "MAE: 1.53\n",
            "RMSE: 2.38\n",
            "\n",
            "Calorie Prediction (neural_net):\n",
            "R2 Score: 0.9989\n",
            "MAE: 1.57\n",
            "RMSE: 2.10\n",
            "\n",
            "==================================================\n",
            "Generating SHAP Explanations\n",
            "==================================================\n",
            "\n",
            "Generating SHAP explanations (traditional)...\n",
            "\n",
            "Generating SHAP explanations (neural_net)...\n",
            "SHAP Error: only integer scalar arrays can be converted to a scalar index\n"
          ]
        }
      ]
    }
  ]
}